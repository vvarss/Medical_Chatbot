# Medical_Chatbot_Using_RAG
## ğŸ¥Medical Chatbot using RAG (Retrieval-Augmented Generation)

An intelligent medical-query assistant built using Retrieval-Augmented Generation (RAG).
This project enhances the accuracy and safety of AI-generated responses by grounding answers in verified medical documents supplied in the vector database.
This chatbot focusses mainly on heart diseases.

## ğŸš€Features
* RAG-powered medical question answering
Uses embeddings + retrieval to generate context-aware, reliable answers from your uploaded medical documents.

* OpenAI API integration
Utilizes OpenAIâ€™s models for embeddings and LLM generation.

* Vector database support
Can be used with ChromaDB / FAISS / Pinecone (depending on your implementation).

* Streaming & follow-up conversations
Maintains chat history for multi-turn conversations.

* Clean modular architecture
Easily extendable for new data sources or new medical specialities.

## ğŸ› ï¸Tech Stack
* Python 3.10+
* OpenAI API (for embeddings + LLM)
### RAG Pipeline
* Document loading â†’ Chunking â†’ Embeddings â†’ Vector Store â†’ Retrieval â†’ LLM
* Vector DB: (Chroma)

## ğŸ”§Installation
```
git clone https://github.com/vvarss/medical-rag-chatbot.git
cd medical-rag-chatbot
```
## ğŸ“šRAG Workflow
* Document ingestion
Loads PDFs/text â†’ cleans â†’ chunks.
* Embedding generation
Each chunk is encoded into vector embeddings using OpenAI.
* Vector storage
Stored in Chroma.
* Retrieval
When the user asks a question, the system finds the most relevant document chunks.
*LLM reasoning
The LLM uses the retrieved medical context + conversation history to generate a safe answer.
## ğŸ›¡ï¸ Safety
* No diagnosis is given.
* No personalised medical instructions.
* Answers are grounded in your uploaded documents.

## ğŸ¤Contributing
Pull requests are welcome!â¤ï¸

Feel free to open issues for feature suggestions or bug reports.
